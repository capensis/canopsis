## New FIFO Engine
FIFO Engine consists of following sub-modules:
* Alarm queues manager
* Persistence manager
* Ack manager
The Alarm queues manager is the main component, which is responsible for managing incomming events. It should be aware of an alarm, which is being modified by the engine pipeline.  

The Persistence manager is a Redis client, that saves alarm locks into Redis database and retrieves alarm lock if it's needed for the Alarm queues manager. Every alarm lock will have a ttl in order to manage the situation where some of the engine in the pipeline was failed and didn't send the ack message. We don't want to keep an alarm lock forever.  
Since we should somehow unlock alarms the engines should send an ack message to the FIFO engine. The trigger event shouldn't send an ack. The new event for the alarm should be sent only after all triggers are finished.  

The Ack manager is responsible for managing ack messages.  

## CHE multi-instance events flow changes
With new Engine_fifo event queue all events processed with engine-fifo engine. This engine dispatches events to CHE   engine in FIFO order, bearing in mind that multiple CHE instances should not process new events for particular `conector/component/resource` until previous event with same `conector/component/resource` processing has not been finished. So there is a Redis storage for locks and event queues storage.  
When event comes Engine_fifo queue it checked first for existed lock. Event stored to queue when it's locked. Event passed to Engine_che when no locks found. Locked and enqueued events wait for ACK messages from engines behind CHE.
ACK message received by engine-fifo engine means finising event processing so next event with same `conector/component/resource` cold be released for pocessing by CHE engine. When ACK has not received during timeout period (lockTtl flag value) the appropriate lock will be expired and FIFO received the message from Redis. This is the reason of the message `"alarm lock has been expired"` in application log. When no locks and no queues for `conector/component/resource` has been found there is regular order for other events. To sum up, the algorithm described above prevents FIFO order violation with events processing by concurrent CHE instances.

#### Engine-fifo lockTtl flag
With this flag you can set up ttl for a record in redis. It was 10 seconds by default, so when we tested the engine-fifo with a big event flow (>1000 events/sec) generated by random-feeder we saw, that engine-axe couldn't process these events fast, so engine-fifo didn't received enough ack messages for the events, so redis unlocked events by ttl and it was too hard for engine-fifo to process those unlocked events simultaneously. The ttl was low for the system, so we decided that in will be useful to have a possibility to change ttl by a flag.
Now it's possible to tune a ttl time.
So the main rule is that if you receive alarm lock has been expired kind of log and everything else is OK, like engines are working and all connections are OK, than ttl time is low, you need to increase it.

#### Depreciated alwaysFlushEntities flag
`alwaysFlushEntities` was removed with making CHE engine stateless. This flag aimed to control cache store policy, and lost its meaning when cache was removed from CHE.

## Deployment
In the section below there are changes need to be done to run and test application.  
A new engine, engine-fifo must be added to docker-compose.yml  

#### An example of new section for docker-compose.yml with new engine-fifo:
```
      fifo:
        image: canopsis/engine-fifo:${CANOPSIS_IMAGE_TAG}
        env_file:
          - compose.env
        restart: unless-stopped
        command: /engine-fifo -redisAddress redis:6379
```

Dockerfile to build image must be the same as for engine-che except directory paths.  
To start with engine-che multiple instances docker-compose can be run with command line arguments:  
`--scale che=N` where N is number of engine-che instances.  
With replacement in .env file *"MONGO_TAG=3.6-jessie"* to *"MONGO_TAG=3.6"* we've got latest revision of MongoDB v3.6  (3.6.17 for the moment) built with newer Go version with significant changes to memory management in Go garbage collector.  
Not only engine-che was changed but other engines were changed too: engine-action, engine-axe, engine-watcher, so respective images have to be re-build as well.  

##### Update RabbitMQ configuration
Events flow has been changed, that "canopsis.changes" exchange has binding with "Engine_fifo" queue instead of "Engine_che". Engine FIFO dispatches incoming events to Che instances, sending them to "Engine_che".
To apply changes into new RabbitMQ installation, initialization.toml and initialization-cat.toml files should be changed:

#### old section:

``` [[RabbitMQ.queues]]
name = "Engine_che"
durable = true
autoDelete = false
exclusive = false
noWait = false
# args =
  [RabbitMQ.queues.bind]
  key = "#"
  exchange = "canopsis.events"
  noWait = false
  # args =
 ``` 
#### new sections:
```
[[RabbitMQ.queues]]
name = "Engine_che"
durable = true
autoDelete = false
exclusive = false
noWait = false
# args =

[[RabbitMQ.queues]]
name = "Engine_fifo"
durable = true
autoDelete = false
exclusive = false
noWait = false
# args =
  [RabbitMQ.queues.bind]
  key = "#"
  exchange = "canopsis.events"
  noWait = false
  # args =

[[RabbitMQ.queues]]
name = "FIFO_ack"
durable = true
autoDelete = false
exclusive = false
noWait = false
# args =
```

Previously existed RabbitMQ configuration must be changed with adding 2 queues to RabbitMQ configuration: Engine_fifo and FIFO_ack. Then canopsis.events exchange bindings must be changed:

add Engine_fifo binding  
remove Engine_che binding  

### Redis Sentinel
`CPS_REDIS_URL` environment variable can contain Redis Sentinel connection URL to provide fail tolerant Redis configuration.
Supported URL form is:  `"redis-sentinel://[password@]host1[:port1][,host2[:port2]][,hostN[:portN]][/database][?[timeout=timeout[d|h|m|s|ms|us|ns]][&sentinelMasterId=sentinelMasterId]]`  
*host1:port1, host2:port2, ... hostN:portN* - are sentinel addresses, mandatory parameter *"sentinelMasterId"* points to master host name, optional parameter *"timeout"* specifies the idle timeout - amount of time after which client closes idle connections, it should be less than server's timeout. Optional *"database"* parameter specifies database number.  
Example: `redis-sentinel://localhost:46379,localhost:46380,localhost:46380/0?sentinelMasterId=mymaster`  
Details of this topic described in the article https://redis.io/topics/sentinel  
URL without *"redis-sentinel://"* prefix (e.g. *"redis://"* prefix or empty prefix) means using standalone Redis instance as it handled before.  

## Testing Che Multi-instance
Previously existed feeder was updated to provide different load profile according to findings we've got from provided customers data dumps. New feeder is /cmd/random-feeder. It uses existed database with default_entities collection. Building initial data for this collection usually takes a long time. Attached dump can be restored with mongorestore before test. random-feeder accepted arguments are:

`opersec` -- events per second
`npersec` -- newly added resources per second

Started with default values it will create 1% new resources from total incoming events stream.